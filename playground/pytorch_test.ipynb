{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.a = nn.Parameter(torch.randn(1, 1, requires_grad=True))  # Learnable parameter a\n",
    "        self.b = nn.Parameter(torch.randn(1, 1, requires_grad=True))  # Learnable parameter b\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.a * x + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learn ax+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0040\n",
      "Epoch [200/1000], Loss: 0.0020\n",
      "Epoch [300/1000], Loss: 0.0010\n",
      "Epoch [400/1000], Loss: 0.0005\n",
      "Epoch [500/1000], Loss: 0.0003\n",
      "Epoch [600/1000], Loss: 0.0001\n",
      "Epoch [700/1000], Loss: 0.0001\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "Learned parameter a: 2.0019\n",
      "Learned parameter b: 0.9930\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "X = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])  # Feature vector\n",
    "y = torch.tensor([[3.0], [5.0], [7.0], [9.0], [11.0]])  # Target vector\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearModel()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Print the learned parameters\n",
    "print(f'Learned parameter a: {model.a.item():.4f}')\n",
    "print(f'Learned parameter b: {model.b.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.6873\n",
      "Epoch [200/1000], Loss: 0.6841\n",
      "Epoch [300/1000], Loss: 0.6822\n",
      "Epoch [400/1000], Loss: 0.6809\n",
      "Epoch [500/1000], Loss: 0.6799\n",
      "Epoch [600/1000], Loss: 0.6789\n",
      "Epoch [700/1000], Loss: 0.6779\n",
      "Epoch [800/1000], Loss: 0.6769\n",
      "Epoch [900/1000], Loss: 0.6759\n",
      "Epoch [1000/1000], Loss: 0.6749\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example data\n",
    "X = torch.randn(100, 5)  # 100 samples, 5 features\n",
    "y = torch.randint(0, 2, (100,)).float()  # Binary target\n",
    "\n",
    "# Define the neural network\n",
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = FeedForwardNet(5, 10, 8, 1)  # Input size 5, hidden sizes 10 and 8, output size 1\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y.unsqueeze(1))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Print progress\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_heads = 2\n",
    "input_dim = 2\n",
    "key_dim = 5\n",
    "batch_size = 2\n",
    "graph_size = 4\n",
    "\n",
    "# Create a sample tensor\n",
    "W = torch.ones(n_heads, input_dim, key_dim) # (n_heads, input_dim, key_dim) = (2, 2, 5)\n",
    "\n",
    "h = torch.ones(batch_size, graph_size, input_dim)\n",
    "\n",
    "hflat = h.contiguous().view(-1, input_dim) # (batch_size * graph_size, input_dim) = (8, 2)\n",
    "\n",
    "out = torch.matmul(hflat, W) # (batch_size * graph_size, key_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]],\n",
       "\n",
       "         [[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]]],\n",
       "\n",
       "\n",
       "        [[[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]],\n",
       "\n",
       "         [[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]]],\n",
       "\n",
       "\n",
       "        [[[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]],\n",
       "\n",
       "         [[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.ones(3,2,2,2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3554,  0.9251],\n",
       "         [-0.7913, -1.1901]],\n",
       "\n",
       "        [[-0.7913, -0.3347],\n",
       "         [-0.0350, -0.0901]],\n",
       "\n",
       "        [[ 0.4142, -0.3328],\n",
       "         [-0.8271,  1.6290]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.2935, -0.5299],\n",
       "         [-6.2935, -0.5299]],\n",
       "\n",
       "        [[-1.6527, -0.8495],\n",
       "         [-1.6527, -0.8495]],\n",
       "\n",
       "        [[-0.8258,  2.5922],\n",
       "         [-0.8258,  2.5922]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones(3,2,2)+1) @ (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.ones(3) @ torch.ones(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2) @ (torch.ones(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.]]],\n",
       "\n",
       "\n",
       "        [[[2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.]],\n",
       "\n",
       "         [[2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.],\n",
       "          [2., 2., 2., 2., 2.]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hflat @ W).view(n_heads, batch_size, graph_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 5])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_heads = 2\n",
    "input_dim = 2\n",
    "key_dim = 5\n",
    "batch_size = 2\n",
    "graph_size = 4\n",
    "\n",
    "# Create a sample tensor\n",
    "W = torch.ones(n_heads, input_dim, key_dim)\n",
    "\n",
    "h = torch.ones(batch_size, graph_size, input_dim)\n",
    "\n",
    "hflat = h.contiguous().view(-1, input_dim)\n",
    "\n",
    "out = torch.matmul(hflat, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 2]),\n",
       " torch.Size([8, 2]),\n",
       " torch.Size([2, 2, 5]),\n",
       " torch.Size([2, 8, 5]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape, hflat.shape, W.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1343, -0.1192,  0.0265],\n",
       "        [-0.2524, -0.0422,  0.9785],\n",
       "        [-0.5827, -1.7806,  1.7354],\n",
       "        [ 0.2570,  1.4897,  1.8424]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1683,  0.1338,  0.4927, -0.4967,  0.5698, -1.4790])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0161, -0.2674, -2.1117,  1.7751],\n",
       "         [ 0.3761,  0.3804,  1.5195,  1.0489],\n",
       "         [-1.3908, -0.8066, -0.4466, -0.7620]],\n",
       "\n",
       "        [[ 0.5718, -0.6892, -1.2683,  0.7038],\n",
       "         [ 0.2249, -0.5766, -0.2630,  0.0182],\n",
       "         [ 0.2342, -1.4991, -0.8797, -0.1346]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0161, -0.2674, -2.1117,  1.7751],\n",
       "        [ 0.3761,  0.3804,  1.5195,  1.0489],\n",
       "        [-1.3908, -0.8066, -0.4466, -0.7620],\n",
       "        [ 0.5718, -0.6892, -1.2683,  0.7038],\n",
       "        [ 0.2249, -0.5766, -0.2630,  0.0182],\n",
       "        [ 0.2342, -1.4991, -0.8797, -0.1346]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0161, -0.2674, -2.1117,  1.7751],\n",
       "         [ 0.3761,  0.3804,  1.5195,  1.0489],\n",
       "         [-1.3908, -0.8066, -0.4466, -0.7620]],\n",
       "\n",
       "        [[ 0.5718, -0.6892, -1.2683,  0.7038],\n",
       "         [ 0.2249, -0.5766, -0.2630,  0.0182],\n",
       "         [ 0.2342, -1.4991, -0.8797, -0.1346]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention_tsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
